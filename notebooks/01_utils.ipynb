{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-showcase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-heavy",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "> General utilities. Should probably split up into `utils.time` and `utils.download`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ab2c31-5d33-41ea-aae4-8d2d71483d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbverbose.showdoc import show_doc  # noqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-arabic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import datetime as dt\n",
    "import email.utils as eut\n",
    "import http.client as httplib\n",
    "import logging\n",
    "from math import radians, tan\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Union\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import requests\n",
    "from astropy.time import Time as ASTROTIME\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "try:\n",
    "    from osgeo import gdal\n",
    "except ImportError:\n",
    "    GDAL_INSTALLED = False\n",
    "    logger.warning(\n",
    "        \"No GDAL found. Some planetary.utils functions not working, but okay.\"\n",
    "    )\n",
    "else:\n",
    "    GDAL_INSTALLED = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-module",
   "metadata": {},
   "source": [
    "## Time format strings\n",
    "\n",
    "First, we define the different format strings these utils convert from and to.\n",
    "\n",
    "An identifier with `xxx_dt_format_xxx` in its name signifies a full `datetime` format as compared to dates only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "nasa_date_format = \"%Y-%j\"\n",
    "nasa_dt_format = nasa_date_format + \"T%H:%M:%S\"\n",
    "nasa_dt_format_with_ms = nasa_dt_format + \".%f\"\n",
    "iso_date_format = \"%Y-%m-%d\"\n",
    "iso_dt_format = iso_date_format + \"T%H:%M:%S\"\n",
    "iso_dt_format_with_ms = iso_dt_format + \".%f\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9593d41d-bfad-474c-9151-d4039b428d60",
   "metadata": {},
   "source": [
    "### NASA date to datetime and ISO\n",
    "\n",
    "What we call NASA data, is the often used `YYYY-JJJ` based format in the Planetary Data System identifying dates via the running number of the day in the year, e.g. \"2010-240\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42359d0-4a8b-4864-95de-5d0338ad0126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _nasa_date_to_datetime(\n",
    "    datestr: str,  # Date string of the form Y-j\n",
    ") -> dt.datetime:\n",
    "    \"Convert date string to datetime.\"\n",
    "    return dt.datetime.strptime(datestr, nasa_date_format)\n",
    "\n",
    "\n",
    "def _nasa_datetime_to_datetime(\n",
    "    datetimestr: str,  # datetime string of the form Y-jTH:M:S\n",
    ") -> dt.datetime:\n",
    "    \"Convert datetime up to seconds to datetime.\"\n",
    "    return dt.datetime.strptime(datetimestr, nasa_dt_format)\n",
    "\n",
    "\n",
    "def _nasa_datetimems_to_datetime(\n",
    "    datetimestr: str,  # datetime string of the form Y-jTH:M:S.xxx\n",
    ") -> dt.datetime:\n",
    "    \"Convert date with millisec to datetime.\"\n",
    "    return dt.datetime.strptime(datetimestr, nasa_dt_format_with_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4760d0-4411-41a7-961f-fbe4cf8a7c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def nasa_time_to_datetime(\n",
    "    inputstr,  # inputstr of format YYYY-jjj, YYYY-jjjTHH:MM:SS or YYYY-jjjTHH:MM:SS.ffffff\n",
    ") -> dt.datetime:\n",
    "    \"User function to convert all kinds of NASA PDS datestrings with day_of_year into datetimes.\"\n",
    "    try:\n",
    "        return _nasa_datetime_to_datetime(inputstr)\n",
    "    except ValueError:\n",
    "        try:\n",
    "            return _nasa_date_to_datetime(inputstr)\n",
    "        except ValueError:\n",
    "            return _nasa_datetimems_to_datetime(inputstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34b0c31-bd09-4181-837e-f091c3be2246",
   "metadata": {},
   "source": [
    "Example dates and times to test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b68759-b195-443c-8c6f-e6d085b737bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa_date = \"2010-110\"\n",
    "iso_date = \"2010-4-20\"\n",
    "nasa_datetime = \"2010-110T10:12:14\"\n",
    "nasa_datetime_with_ms = nasa_datetime + \".123000\"\n",
    "iso_datetime = \"2010-04-20T10:12:14\"\n",
    "iso_datetime_with_ms = iso_datetime + \".123000\"\n",
    "nasa_times = [nasa_date, nasa_datetime, nasa_datetime_with_ms]\n",
    "iso_times = [iso_date, iso_datetime, iso_datetime_with_ms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a453f80a-8a70-4b67-9d2e-2e8db734e8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert nasa_time_to_datetime(nasa_date) == dt.datetime(2010, 4, 20, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866b3914-b575-4499-8ae7-4c45ddfb5d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert nasa_time_to_datetime(nasa_datetime) == dt.datetime(2010, 4, 20, 10, 12, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fa34d5-f841-4747-a240-91ec44423c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert nasa_time_to_datetime(nasa_datetime_with_ms) == dt.datetime(\n",
    "    2010, 4, 20, 10, 12, 14, 123000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ada8848-5414-4e1b-8171-6d856a3d4339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def nasa_time_to_iso(\n",
    "    inputstr: str,\n",
    "    with_hours: bool = False,  # Switch if return is wanted with hours (i.e. isoformat)\n",
    ") -> str:  # Datestring in ISO-format.\n",
    "    \"\"\"Convert the day-number based NASA datetime format to ISO\"\"\"\n",
    "    has_hours = False\n",
    "    # check if input has hours\n",
    "    try:\n",
    "        res = _nasa_date_to_datetime(inputstr)\n",
    "    except ValueError:\n",
    "        has_hours = True\n",
    "    time = nasa_time_to_datetime(inputstr)\n",
    "    if has_hours or with_hours is True:\n",
    "        return time.isoformat()\n",
    "    else:\n",
    "        return time.strftime(iso_date_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb4637f-b5c8-49bf-b727-769cd7bede0a",
   "metadata": {},
   "source": [
    "Conversions to ISO format, but not providing hours if they are not in input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd341241-8ed0-466f-a7f7-b84775efa83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 2010-110\n",
      "2010-04-20\n",
      "Input: 2010-110T10:12:14\n",
      "2010-04-20T10:12:14\n",
      "Input: 2010-110T10:12:14.123000\n",
      "2010-04-20T10:12:14.123000\n"
     ]
    }
   ],
   "source": [
    "for t in nasa_times:\n",
    "    print(\"Input:\", t)\n",
    "    print(nasa_time_to_iso(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de04b1d7-39ce-47af-a14a-9baa04b3625b",
   "metadata": {},
   "source": [
    "If hours are wanted in the isostring, use `with_hours=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b7016-6e46-457d-9a3e-9553a372dc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 2010-110\n",
      "2010-04-20T00:00:00\n",
      "Input: 2010-110T10:12:14\n",
      "2010-04-20T10:12:14\n",
      "Input: 2010-110T10:12:14.123000\n",
      "2010-04-20T10:12:14.123000\n"
     ]
    }
   ],
   "source": [
    "for t in nasa_times:\n",
    "    print(\"Input:\", t)\n",
    "    print(nasa_time_to_iso(t, with_hours=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-bleeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert nasa_time_to_iso(nasa_date, with_hours=True) == \"2010-04-20T00:00:00\"\n",
    "assert nasa_time_to_iso(nasa_date) == \"2010-04-20\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6c18e9-4414-4ce8-a10a-f7ca8d7e8b97",
   "metadata": {},
   "source": [
    "### ISO date to \"NASA-format\"\n",
    "\n",
    "Again, with NASA-format, we mean the ofen used (in PDS and mission files) YYYY-JJJ format, e.g. \"2010-240\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def iso_to_nasa_time(\n",
    "    inputstr: str,  # Date string of the form Y-m-d\n",
    ") -> str:  # Datestring in NASA standard yyyy-jjj\n",
    "    \"Convert iso date to day-number based NASA date.\"\n",
    "    try:\n",
    "        date = dt.datetime.strptime(inputstr, iso_date_format)\n",
    "    except ValueError:\n",
    "        try:\n",
    "            date = dt.datetime.strptime(inputstr, iso_dt_format)\n",
    "        except ValueError:\n",
    "            date = dt.datetime.strptime(inputstr, iso_dt_format_with_ms)\n",
    "            return date.strftime(nasa_dt_format_with_ms)\n",
    "        else:\n",
    "            return date.strftime(nasa_dt_format)\n",
    "    else:\n",
    "        return date.strftime(nasa_date_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def iso_to_nasa_datetime(\n",
    "    dtimestr: str,  # Datetime string of the form yyyy-mm-ddTHH-MM-SS\n",
    "):  # Datestring in NASA standard yyyy-jjjTHH-MM-SS\n",
    "    \"Convert iso datetime to day-number based NASA datetime.\"\n",
    "    try:\n",
    "        dtimestr.split(\".\")[1]\n",
    "    except IndexError:\n",
    "        source_format = iso_dt_format\n",
    "        target_format = nasa_dt_format\n",
    "    else:\n",
    "        source_format = iso_dt_format_with_ms\n",
    "        target_format = nasa_dt_format_with_ms\n",
    "    date = dt.datetime.strptime(dtimestr, source_format)\n",
    "    return date.strftime(target_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57538342-f7c5-4bd3-ba03-fc58c3a0cdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 2010-4-20\n",
      "2010-110\n",
      "Input: 2010-04-20T10:12:14\n",
      "2010-110T10:12:14\n",
      "Input: 2010-04-20T10:12:14.123000\n",
      "2010-110T10:12:14.123000\n"
     ]
    }
   ],
   "source": [
    "for t in iso_times:\n",
    "    print(\"Input:\", t)\n",
    "    print(iso_to_nasa_time(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert iso_to_nasa_time(iso_date) == nasa_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-italic",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert nasa_time_to_iso(nasa_datetime) == iso_datetime\n",
    "assert nasa_time_to_iso(nasa_datetime_with_ms) == iso_datetime_with_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-salem",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert iso_to_nasa_time(iso_datetime) == nasa_datetime\n",
    "assert iso_to_nasa_time(iso_datetime_with_ms) == nasa_datetime_with_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa22bfd3-1774-4272-9cc8-548fb421e283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def replace_all_nasa_times(\n",
    "    df: pd.DataFrame,  # DataFrame with NASA time columns\n",
    "):\n",
    "    \"\"\"Find all NASA times in dataframe and replace with ISO.\n",
    "\n",
    "    Changes will be implemented on incoming dataframe!\n",
    "\n",
    "    This will be done for all columns with the word TIME in the column name.\n",
    "    \"\"\"\n",
    "    for col in [col for col in df.columns if \"TIME\" in col]:\n",
    "        if \"T\" in df[col].iloc[0]:\n",
    "            df[col] = pd.to_datetime(df[col].map(nasa_time_to_iso))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabc0ee8-7058-4acf-847b-9610fc50abc3",
   "metadata": {},
   "source": [
    "## Network utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2c4edf-347b-46e6-8825-3bc279565235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parse_http_date(\n",
    "    text: str,  # datestring from urllib.request\n",
    ") -> dt.datetime:  # dt.datetime object from given datetime string\n",
    "    \"Parse date string retrieved via urllib.request.\"\n",
    "    return dt.datetime(*eut.parsedate(text)[:6])\n",
    "\n",
    "\n",
    "def get_remote_timestamp(\n",
    "    url: str,  # URL to check timestamp for\n",
    ") -> dt.datetime:\n",
    "    \"\"\"Get the timestamp of a remote file.\n",
    "\n",
    "    Useful for checking if there's an updated file available.\n",
    "    \"\"\"\n",
    "    with urlopen(url, timeout=10) as conn:\n",
    "        t = parse_http_date(conn.headers[\"last-modified\"])\n",
    "    return t\n",
    "\n",
    "\n",
    "def check_url_exists(url):\n",
    "    response = requests.head(url)\n",
    "    if response.status_code < 400:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def url_retrieve(\n",
    "    url: str,  # The URL to download\n",
    "    outfile: str,  # The path where to store the downloaded file.\n",
    "    # The size of the chunk for the request.iter_content call. Default: 128\n",
    "    chunk_size: int = 128,\n",
    "):\n",
    "    \"\"\"Improved urlretrieve with progressbar, timeout and chunker.\n",
    "\n",
    "    This downloader has built-in progress bar using tqdm and using the `requests`\n",
    "    package it improves standard `urllib` behavior by adding time-out capability.\n",
    "\n",
    "    I tested different chunk_sizes and most of the time 128 was actually fastest, YMMV.\n",
    "\n",
    "    Inspired by https://stackoverflow.com/a/61575758/680232\n",
    "    \"\"\"\n",
    "    R = requests.get(url, stream=True, allow_redirects=True)\n",
    "    if R.status_code != 200:\n",
    "        raise ConnectionError(f\"Could not download {url}\\nError code: {R.status_code}\")\n",
    "    with tqdm.wrapattr(\n",
    "        open(outfile, \"wb\"),\n",
    "        \"write\",\n",
    "        miniters=1,\n",
    "        total=int(R.headers.get(\"content-length\", 0)),\n",
    "        desc=str(Path(outfile).name) + \"\\n\",\n",
    "    ) as fd:\n",
    "        for chunk in R.iter_content(chunk_size=chunk_size):\n",
    "            fd.write(chunk)\n",
    "\n",
    "\n",
    "def have_internet():\n",
    "    \"\"\"Fastest way to check for active internet connection.\n",
    "\n",
    "    From https://stackoverflow.com/a/29854274/680232\n",
    "    \"\"\"\n",
    "    conn = httplib.HTTPConnection(\"www.google.com\", timeout=5)\n",
    "    try:\n",
    "        conn.request(\"HEAD\", \"/\")\n",
    "        conn.close()\n",
    "        return True\n",
    "    except:\n",
    "        conn.close()\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a764e2-0ed9-42f4-8e56-fe73801ddaa8",
   "metadata": {},
   "source": [
    "## Image processing helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed487b52-99f9-4448-b281-8e54fcec6948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def height_from_shadow(\n",
    "    shadow_in_pixels: float,  # Measured length of shadow in pixels\n",
    "    sun_elev: float,  # Ange of sun over horizon in degrees\n",
    ") -> float:  # Height [meter]\n",
    "    \"\"\"Calculate height of an object from its shadow length.\n",
    "\n",
    "    Note, that your image might have been binned.\n",
    "    You need to correct `shadow_in_pixels` for that.\n",
    "    \"\"\"\n",
    "    return tan(radians(sun_elev)) * shadow_in_pixels\n",
    "\n",
    "\n",
    "def get_gdal_center_coords(\n",
    "    imgpath: Union[str, Path],  # Path to raster image that is readable by GDLA\n",
    ") -> Tuple[int, int]:  # center row/col coordinates.\n",
    "    \"\"\"Get center rows/cols pixel coordinate for GDAL-readable dataset.\n",
    "\n",
    "    Check CLI `gdalinfo --formats` to see all formats that GDAL can open.\n",
    "    \"\"\"\n",
    "    if not GDAL_INSTALLED:\n",
    "        logger.error(\"GDAL not installed. Returning\")\n",
    "        return\n",
    "    ds = gdal.Open(str(imgpath))\n",
    "    xmean = ds.RasterXSize // 2\n",
    "    ymean = ds.RasterYSize // 2\n",
    "    return xmean, ymean\n",
    "\n",
    "\n",
    "def file_variations(\n",
    "    filename: Union[str, Path],  # The original filename to use as a base.\n",
    "    extensions: list,\n",
    ") -> list:  # list of Paths\n",
    "    \"\"\"Create a variation of file names.\n",
    "\n",
    "    Generate a list of variations on a filename by replacing the extension with\n",
    "    the provided list.\n",
    "\n",
    "    Adapted from T. Olsens `file_variations of the pysis module for using pathlib.\n",
    "    \"\"\"\n",
    "    return [Path(filename).with_suffix(extension) for extension in extensions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2766e4-724c-4308-88cc-741bcae6f75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"abc.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e96b5a-6a79-416c-9314-aaa9dbc8bfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "extensions = \".cub .cal.cub .map.cal.cub\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77119135-7450-4e69-acf7-297218a2052a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('abc.cub'), Path('abc.cal.cub'), Path('abc.map.cal.cub')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_variations(fname, extensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6725282d-24c8-4742-8b60-6f4d268d4a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(extensions) == len(file_variations(fname, extensions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8c8f9c-3f44-49a9-89c3-0b3e04584cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

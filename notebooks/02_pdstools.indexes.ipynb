{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-oakland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp pdstools.indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-swedish",
   "metadata": {},
   "source": [
    "# PDSTools Indexes\n",
    "\n",
    "> Support tools to work with PDS index files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-pension",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'config' from 'planetarypy.config' (/home/maye/Dropbox/src/nbplanetary/planetarypy/config.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f03ba2fc1aa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdateutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplanetarypy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mplanetarypy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'config' from 'planetarypy.config' (/home/maye/Dropbox/src/nbplanetary/planetarypy/config.py)"
     ]
    }
   ],
   "source": [
    "# export\n",
    "import copy\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlsplit, urlunsplit\n",
    "\n",
    "import pandas as pd\n",
    "import pvl\n",
    "from dateutil import parser\n",
    "from planetarypy import utils\n",
    "from planetarypy.config import config\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "try:\n",
    "    # 3.6 compatibility\n",
    "    from importlib_resources import path as resource_path\n",
    "except ModuleNotFoundError:\n",
    "    from importlib.resources import path as resource_path\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "indices_root = Path(config.data_archive) / \"indices\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-humanitarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/maye/big_drive/planetary_data/planetarypy/indices')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "indices_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-entertainment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@dataclass\n",
    "class Index:\n",
    "    \"\"\"Index manager class.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    key : str\n",
    "        Nested key in form of mission.instrument.index_name\n",
    "    url : str\n",
    "        URL to index\n",
    "    timestamp : str\n",
    "        Timestamp in ISO time format yy-mm-ddTHH:MM:SS.\n",
    "        This is usually read by the IndexDB class from the config file and its\n",
    "        value is the time of the last download.\n",
    "    \"\"\"\n",
    "\n",
    "    local_root = indices_root\n",
    "    key: str\n",
    "    url: str\n",
    "    timestamp: str\n",
    "\n",
    "    @property\n",
    "    def needs_download(self):\n",
    "        \"\"\"Determine if the index needs to be downloaded.\n",
    "\n",
    "        Download shall happen when\n",
    "        (1) no local timestamp was stored or\n",
    "        (2) when the remote timestamp is newer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        index : indices.Index (namedtuple)\n",
    "            Index holding the timestamp attribute read from the config file\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        bool\n",
    "            Boolean indicating if download shall happen.\n",
    "        \"\"\"\n",
    "        remote_timestamp = utils.get_remote_timestamp(self.url)\n",
    "        self.new_timestamp = remote_timestamp\n",
    "        if self.timestamp:\n",
    "            if remote_timestamp > parser.parse(self.timestamp):\n",
    "                return True\n",
    "        else:\n",
    "            # also return True when the timestamp is not valid\n",
    "            return True\n",
    "        # all other cases no D/L required\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def key_tokens(self):\n",
    "        return self.key.split(\".\")\n",
    "\n",
    "    @property\n",
    "    def mission(self):\n",
    "        return self.key_tokens[0]\n",
    "\n",
    "    @property\n",
    "    def instrument(self):\n",
    "        return self.key_tokens[1]\n",
    "\n",
    "    @property\n",
    "    def index_name(self):\n",
    "        \"str: Examples: EDR, RDR\"\n",
    "        return self.key_tokens[2]\n",
    "\n",
    "    @property\n",
    "    def label_filename(self):\n",
    "        return Path(self.url.split(\"/\")[-1])\n",
    "\n",
    "    @property\n",
    "    def isupper(self):\n",
    "        return self.label_filename.suffix.isupper()\n",
    "\n",
    "    @property\n",
    "    def table_filename(self):\n",
    "        new_suffix = \".TAB\" if self.isupper else \".tab\"\n",
    "        return self.label_filename.with_suffix(new_suffix)\n",
    "\n",
    "    @property\n",
    "    def label_path(self):\n",
    "        return Path(urlsplit(self.url).path)\n",
    "\n",
    "    @property\n",
    "    def table_path(self):\n",
    "        return self.label_path.with_name(self.table_filename.name)\n",
    "\n",
    "    @property\n",
    "    def table_url(self):\n",
    "        tokens = urlsplit(self.url)\n",
    "        return urlunsplit(\n",
    "            tokens._replace(\n",
    "                path=str(self.label_path.with_name(self.table_filename.name))\n",
    "            )\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def local_dir(self):\n",
    "        p = self.local_root / f\"{self.mission}/{self.instrument}/{self.index_name}\"\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "        return p\n",
    "\n",
    "    @property\n",
    "    def local_table_path(self):\n",
    "        return self.local_dir / self.table_filename\n",
    "\n",
    "    @property\n",
    "    def local_label_path(self):\n",
    "        return self.local_dir / self.label_filename\n",
    "\n",
    "    @property\n",
    "    def local_hdf_path(self):\n",
    "        return self.local_table_path.with_suffix(\".hdf\")\n",
    "\n",
    "    @property\n",
    "    def df(self):\n",
    "        return pd.read_hdf(self.local_hdf_path)\n",
    "\n",
    "    def download(self, local_dir=\"\", convert_to_hdf=True, force_update=False):\n",
    "        \"\"\"Wrapping URLs for downloading PDS indices and their label files.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        key : str, optional\n",
    "            Period-separated key into the available index files, e.g. cassini.uvis.moon_summary\n",
    "        label_url : str, optional\n",
    "            Alternative to using the index system, the user can provide the URL to a label\n",
    "            for an index. The table file has to be in the same folder, as usual.\n",
    "        local_dir: str, pathlib.Path, optional\n",
    "            Path for local storage. Default: current directory and filename from URL\n",
    "        convert_to_hdf : bool\n",
    "            Switch to convert the index automatically to a faster loading HDF file\n",
    "        \"\"\"\n",
    "        if not local_dir:\n",
    "            local_dir = self.local_dir\n",
    "        # check timestamp\n",
    "        if not self.needs_download and not force_update:\n",
    "            print(\"Stored index is up-to-date.\")\n",
    "            return\n",
    "        label_url = self.url\n",
    "        logger.info(\"Downloading %s.\" % label_url)\n",
    "        local_label_path, _ = utils.download(label_url, local_dir)\n",
    "        logger.info(\"Downloading %s.\", self.table_url)\n",
    "        local_data_path, _ = utils.download(self.table_url, local_dir)\n",
    "        IndexDB().update_timestamp(self)\n",
    "        if convert_to_hdf is True:\n",
    "            self.convert_to_hdf()\n",
    "            print(f\"Downloaded and converted to pandas HDF: {savepath}\")\n",
    "        else:\n",
    "            print(f\"Downloaded {local_label_path} and {local_data_path}\")\n",
    "\n",
    "    def convert_to_hdf(self):\n",
    "        label = IndexLabel(self.local_label_path)\n",
    "        df = label.read_index_data()\n",
    "        df.to_hdf(self.local_hdf_path, \"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class IndexDB:\n",
    "    \"\"\"Handles the configuration file with the URLs to indexes.\"\"\"\n",
    "    fname = \".pds_indices_db.toml\"\n",
    "    fpath = Path.home() / fname\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize index database.\n",
    "\n",
    "        Will copy the package's version to user's home folder at init,\n",
    "        so that user doesn't need to edit file in package to add new indices.\n",
    "\n",
    "        Adding new index URLs to the package's config file pds_indices_db.toml\n",
    "        is highly encouraged via pull request.\n",
    "        \"\"\"\n",
    "        self.config = self.rea\n",
    "\n",
    "\n",
    "    def set_dict_value(self, nested_key, value):\n",
    "        \"\"\"Set a nested dictionary key to new value.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        nested_key : str\n",
    "            A nested key in the toml format, separated by '.', e.g. cassini.uvis.summary\n",
    "        value : str\n",
    "            New value for dictionary key\n",
    "        \"\"\"\n",
    "        dic = self.config\n",
    "        keys = nested_key.split(\".\")\n",
    "        for key in keys[:-1]:\n",
    "            dic = dic.setdefault(key, {})\n",
    "        dic[keys[-1]] = value\n",
    "\n",
    "    def list_indices(self):\n",
    "        \"Print index database in pretty form, using toml.dumps\"\n",
    "        print(toml.dumps(self.config))\n",
    "        print(\n",
    "            \"Use indices.download('mission.instrument.index') to download in index file.\"\n",
    "        )\n",
    "        print(\"For example: indices.download('cassini.uvis.moon_summary'\")\n",
    "\n",
    "    def update_timestamp(self, index):\n",
    "        self.set_dict_value(f\"{index.key}.timestamp\", index.new_timestamp.isoformat())\n",
    "        self.write_to_file()\n",
    "\n",
    "    def download(self, key, **kwargs):\n",
    "        \"\"\"Wrapping Index.download().\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        key: str, optional\n",
    "            Period-separated key into the available index files, e.g. cassini.uvis.moon_summary\n",
    "        kwargs: dict\n",
    "            Given to Index.download()\n",
    "        \"\"\"\n",
    "        index = self.get_by_path(key)\n",
    "        index.download()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return toml.dumps(self.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-guatemala",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"IndexDB.__init__\" class=\"doc_header\"><code>IndexDB.__init__</code><a href=\"__main__.py#L9\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>IndexDB.__init__</code>()\n",
       "\n",
       "```\n",
       "Initialize index database.\n",
       "\n",
       "Will copy the package's version to user's home folder at init,\n",
       "so that user doesn't need to edit file in package to add new indices.\n",
       "\n",
       "Adding new index URLs to the package's config file pds_indices_db.toml\n",
       "is highly encouraged via pull request.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(IndexDB.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-effectiveness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"IndexDB.read_from_file\" class=\"doc_header\"><code>IndexDB.read_from_file</code><a href=\"__main__.py#L24\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>IndexDB.read_from_file</code>(**`path`**=*`None`*)\n",
       "\n",
       "```\n",
       "Read the config.\n",
       "\n",
       "Writing this short method to decouple IndexDB from choice of config file format.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "path : str, pathlib.Path\n",
       "    Path to the config file to open.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(IndexDB.read_from_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-wells",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"IndexDB.get_index\" class=\"doc_header\"><code>IndexDB.get_index</code><a href=\"__main__.py#L44\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>IndexDB.get_index</code>(**`nested_key`**)\n",
       "\n",
       "```\n",
       "Get sub-dictionary by nested key.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "nested_key: str\n",
       "    A nested key in the toml format, separated by '.', e.g. cassini.uvis.ring_summary\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(IndexDB.get_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-upper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"IndexDB.set_dict_value\" class=\"doc_header\"><code>IndexDB.set_dict_value</code><a href=\"__main__.py#L58\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>IndexDB.set_dict_value</code>(**`nested_key`**, **`value`**)\n",
       "\n",
       "```\n",
       "Set a nested dictionary key to new value.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "nested_key : str\n",
       "    A nested key in the toml format, separated by '.', e.g. cassini.uvis.summary\n",
       "value : str\n",
       "    New value for dictionary key\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(IndexDB.set_dict_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-champion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"IndexDB.list_indices\" class=\"doc_header\"><code>IndexDB.list_indices</code><a href=\"__main__.py#L74\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>IndexDB.list_indices</code>()\n",
       "\n",
       "```\n",
       "Print index database in pretty form, using toml.dumps\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(IndexDB.list_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-vertical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"IndexDB.write_to_file\" class=\"doc_header\"><code>IndexDB.write_to_file</code><a href=\"__main__.py#L39\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>IndexDB.write_to_file</code>()\n",
       "\n",
       "```\n",
       "Write the config to user's home copy.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(IndexDB.write_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "indexdb = IndexDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-advocacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def list_available_index_files():\n",
    "    \"\"\"This function lists all supported index files.\n",
    "\n",
    "    TODO: Maybe some nice collapsible HTML view for inside notebooks.\n",
    "    \"\"\"\n",
    "    print(indexdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-vietnamese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cassini.iss.index]\n",
      "url = \"https://pds-rings.seti.org/holdings/metadata/COISS_2xxx/COISS_2999/COISS_2999_index.lbl\"\n",
      "timestamp = \"2019-11-19T23:37:22\"\n",
      "\n",
      "[cassini.iss.inventory]\n",
      "url = \"https://pds-rings.seti.org/holdings/metadata/COISS_2xxx/COISS_2999/COISS_2999_inventory.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[cassini.iss.moon_summary]\n",
      "url = \"https://pds-rings.seti.org/holdings/metadata/COISS_2xxx/COISS_2999/COISS_2999_moon_summary.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[cassini.iss.ring_summary]\n",
      "url = \"https://pds-rings.seti.org/holdings/metadata/COISS_2xxx/COISS_2999/COISS_2999_ring_summary.lbl\"\n",
      "timestamp = \"2019-06-08T16:29:20\"\n",
      "\n",
      "[cassini.iss.saturn_summary]\n",
      "url = \"https://pds-rings.seti.org/holdings/metadata/COISS_2xxx/COISS_2999/COISS_2999_saturn_summary.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[cassini.uvis.index]\n",
      "url = \"https://pds-rings.seti.org/holdings/metadata/COUVIS_0xxx/COUVIS_0999/COUVIS_0999_index.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[cassini.uvis.moon_summary]\n",
      "url = \"https://pds-rings.seti.org/holdings/metadata/COUVIS_0xxx/COUVIS_0999/COUVIS_0999_moon_summary.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[cassini.uvis.ring_summary]\n",
      "url = \"https://pds-rings.seti.org/holdings/metadata/COUVIS_0xxx/COUVIS_0999/COUVIS_0999_ring_summary.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[cassini.uvis.saturn_summary]\n",
      "url = \"https://pds-rings.seti.org/holdings/metadata/COUVIS_0xxx/COUVIS_0999/COUVIS_0999_saturn_summary.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[cassini.uvis.supplemental_index]\n",
      "url = \"https://pds-rings.seti.org/holdings/metadata/COUVIS_0xxx/COUVIS_0999/COUVIS_0999_supplemental_index.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[mro.hirise.dtm]\n",
      "url = \"https://hirise-pds.lpl.arizona.edu/PDS/INDEX/DTMCUMINDEX.LBL\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[mro.hirise.edr]\n",
      "url = \"https://hirise-pds.lpl.arizona.edu/PDS/INDEX/EDRCUMINDEX.LBL\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[mro.hirise.rdr]\n",
      "url = \"https://hirise-pds.lpl.arizona.edu/PDS/INDEX/RDRCUMINDEX.LBL\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[lro.diviner.edr1]\n",
      "url = \"https://pds-geosciences.wustl.edu/lro/lro-l-dlre-2-edr-v1/lrodlr_0001/index/index.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[lro.diviner.edr2]\n",
      "url = \"https://pds-geosciences.wustl.edu/lro/lro-l-dlre-2-edr-v1/lrodlr_0002/index/index.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[lro.diviner.rdr1]\n",
      "url = \"https://pds-geosciences.wustl.edu/lro/lro-l-dlre-4-rdr-v1/lrodlr_1001/index/rdrindex.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[lro.diviner.rdr2]\n",
      "url = \"https://pds-geosciences.wustl.edu/lro/lro-l-dlre-4-rdr-v1/lrodlr_1002/index/rdrindex.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[lro.lola.edr]\n",
      "url = \"http://pds-geosciences.wustl.edu/lro/lro-l-lola-2-edr-v1/lrolol_0xxx/index/edrindex.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[lro.lola.rdr]\n",
      "url = \"http://pds-geosciences.wustl.edu/lro/lro-l-lola-3-rdr-v1/lrolol_1xxx/index/rdrindex.lbl\"\n",
      "timestamp = \"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_available_index_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-nancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class PVLColumn(object):\n",
    "    \"\"\"Manages just one of the columns in a table that is described via PVL.\"\"\"\n",
    "\n",
    "    def __init__(self, pvlobj):\n",
    "        self.pvlobj = pvlobj\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self.pvlobj[\"NAME\"]\n",
    "\n",
    "    @property\n",
    "    def name_as_list(self):\n",
    "        \"needs to return a list for consistency for cases when it's an array.\"\n",
    "        if self.items is None:\n",
    "            return [self.name]\n",
    "        else:\n",
    "            return [self.name + \"_\" + str(i + 1) for i in range(self.items)]\n",
    "\n",
    "    @property\n",
    "    def start(self):\n",
    "        \"Decrease by one as Python is 0-indexed.\"\n",
    "        return self.pvlobj[\"START_BYTE\"] - 1\n",
    "\n",
    "    @property\n",
    "    def stop(self):\n",
    "        return self.start + self.pvlobj[\"BYTES\"]\n",
    "\n",
    "    @property\n",
    "    def items(self):\n",
    "        return self.pvlobj.get(\"ITEMS\")\n",
    "\n",
    "    @property\n",
    "    def item_bytes(self):\n",
    "        return self.pvlobj.get(\"ITEM_BYTES\")\n",
    "\n",
    "    @property\n",
    "    def item_offset(self):\n",
    "        return self.pvlobj.get(\"ITEM_OFFSET\")\n",
    "\n",
    "    @property\n",
    "    def colspecs(self):\n",
    "        if self.items is None:\n",
    "            return (self.start, self.stop)\n",
    "        else:\n",
    "            i = 0\n",
    "            bucket = []\n",
    "            for _ in range(self.items):\n",
    "                off = self.start + self.item_offset * i\n",
    "                bucket.append((off, off + self.item_bytes))\n",
    "                i += 1\n",
    "            return bucket\n",
    "\n",
    "    def decode(self, linedata):\n",
    "        if self.items is None:\n",
    "            start, stop = self.colspecs\n",
    "            return linedata[start:stop]\n",
    "        else:\n",
    "            bucket = []\n",
    "            for (start, stop) in self.colspecs:\n",
    "                bucket.append(linedata[start:stop])\n",
    "            return bucket\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.pvlobj.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class IndexLabel(object):\n",
    "    \"\"\"Support working with label files of PDS Index tables.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labelpath : str, pathlib.Path\n",
    "        Path to the labelfile for a PDS Indexfile. The actual table should reside in the same\n",
    "        folder to be automatically parsed when calling the `read_index_data` method.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, labelpath):\n",
    "        self.path = Path(labelpath)\n",
    "        \"search for table name pointer and store key and fpath.\"\n",
    "        tuple = [i for i in self.pvl_lbl if i[0].startswith(\"^\")][0]\n",
    "        self.tablename = tuple[0][1:]\n",
    "        self.index_name = tuple[1]\n",
    "\n",
    "    @property\n",
    "    def index_path(self):\n",
    "        return self.path.parent / self.index_name\n",
    "\n",
    "    @property\n",
    "    def pvl_lbl(self):\n",
    "        return pvl.load(str(self.path))\n",
    "\n",
    "    @property\n",
    "    def table(self):\n",
    "        return self.pvl_lbl[self.tablename]\n",
    "\n",
    "    @property\n",
    "    def pvl_columns(self):\n",
    "        return self.table.getlist(\"COLUMN\")\n",
    "\n",
    "    @property\n",
    "    def columns_dic(self):\n",
    "        return {col[\"NAME\"]: col for col in self.pvl_columns}\n",
    "\n",
    "    @property\n",
    "    def colnames(self):\n",
    "        \"\"\"Read the columns in an PDS index label file.\n",
    "\n",
    "        The label file for the PDS indices describes the content\n",
    "        of the index files.\n",
    "        \"\"\"\n",
    "        colnames = []\n",
    "        for col in self.pvl_columns:\n",
    "            colnames.extend(PVLColumn(col).name_as_list)\n",
    "        return colnames\n",
    "\n",
    "    @property\n",
    "    def colspecs(self):\n",
    "        colspecs = []\n",
    "        columns = self.table.getlist(\"COLUMN\")\n",
    "        for column in columns:\n",
    "            pvlcol = PVLColumn(column)\n",
    "            if pvlcol.items is None:\n",
    "                colspecs.append(pvlcol.colspecs)\n",
    "            else:\n",
    "                colspecs.extend(pvlcol.colspecs)\n",
    "        return colspecs\n",
    "\n",
    "    def read_index_data(self, convert_times=True):\n",
    "        return index_to_df(self.index_path, self, convert_times=convert_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def index_to_df(indexpath, label, convert_times=True):\n",
    "    \"\"\"The main reader function for PDS Indexfiles.\n",
    "\n",
    "    In conjunction with an IndexLabel object that figures out the column widths,\n",
    "    this reader should work for all PDS TAB files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    indexpath : str or pathlib.Path\n",
    "        The path to the index TAB file.\n",
    "    label : pdstools.IndexLabel object\n",
    "        Label object that has both the column names and the columns widths as attributes\n",
    "        'colnames' and 'colspecs'\n",
    "    convert_times : bool\n",
    "        Switch to control if to convert columns with \"TIME\" in name (unless COUNT is as well in name) to datetime\n",
    "    \"\"\"\n",
    "    indexpath = Path(indexpath)\n",
    "    df = pd.read_fwf(\n",
    "        indexpath, header=None, names=label.colnames, colspecs=label.colspecs\n",
    "    )\n",
    "    if convert_times:\n",
    "        for column in [i for i in df.columns if \"TIME\" in i and \"COUNT\" not in i]:\n",
    "            if column == \"LOCAL_TIME\":\n",
    "                # don't convert local time\n",
    "                continue\n",
    "            print(f\"Converting times for column {column}.\")\n",
    "            try:\n",
    "                df[column] = pd.to_datetime(df[column])\n",
    "            except ValueError:\n",
    "                df[column] = pd.to_datetime(\n",
    "                    df[column], format=utils.nasa_dt_format_with_ms, errors=\"coerce\"\n",
    "                )\n",
    "        print(\"Done.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def decode_line(linedata, labelpath):\n",
    "    \"\"\"Decode one line of tabbed data with the appropriate label file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    linedata : str\n",
    "        One line of a .tab data file\n",
    "    labelpath : str or pathlib.Path\n",
    "        Path to the appropriate label that describes the data.\n",
    "    \"\"\"\n",
    "    label = IndexLabel(labelpath)\n",
    "    for column in label.pvl_columns:\n",
    "        pvlcol = PVLColumn(column)\n",
    "        print(pvlcol.name, pvlcol.decode(linedata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def find_mixed_type_cols(df, fix=True):\n",
    "    \"\"\"For a given dataframe, find the columns that are of mixed type.\n",
    "\n",
    "    Tool to help with the performance warning when trying to save a pandas DataFrame as a HDF.\n",
    "    When a column changes datatype somewhere, pickling occurs, slowing down the reading process of the HDF file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Dataframe to be searched for mixed data-types\n",
    "    fix : bool\n",
    "        Switch to control if NaN values in these problem columns should be replaced by the string 'UNKNOWN'\n",
    "    Returns\n",
    "    -------\n",
    "    List of column names that have data type changes within themselves.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for col in df.columns:\n",
    "        weird = (df[[col]].applymap(type) != df[[col]].iloc[0].apply(type)).any(axis=1)\n",
    "        if len(df[weird]) > 0:\n",
    "            print(col)\n",
    "            result.append(col)\n",
    "    if fix is True:\n",
    "        for col in result:\n",
    "            df[col].fillna(\"UNKNOWN\", inplace=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-alberta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def fix_hirise_edrcumindex(infname, outfname):\n",
    "    \"\"\"Fix HiRISE EDRCUMINDEX.\n",
    "\n",
    "    The HiRISE EDRCUMINDEX has some broken lines where the SCAN_EXPOSURE_DURATION is of format\n",
    "    F10.4 instead of the defined F9.4.\n",
    "    This function simply replaces those incidences with one less decimal fraction, so 20000.0000\n",
    "    becomes 20000.000.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    infname : str\n",
    "        Path to broken EDRCUMINDEX.TAB\n",
    "    outfname : str\n",
    "        Path where to store the fixed TAB file\n",
    "    \"\"\"\n",
    "    with open(infname) as f:\n",
    "        with open(outfname, \"w\") as newf:\n",
    "            for line in tqdm(f):\n",
    "                exp = line.split(\",\")[21]\n",
    "                if float(exp) > 9999.999:\n",
    "                    # catching the return of write into dummy variable\n",
    "                    _ = newf.write(line.replace(exp, exp[:9]))\n",
    "                else:\n",
    "                    _ = newf.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"cassini.iss.index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-transcript",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(key='cassini.iss.index', url='https://pds-rings.seti.org/holdings/metadata/COISS_2xxx/COISS_2999/COISS_2999_index.lbl', timestamp='2019-11-19T23:37:22')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = indexdb.get(key)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-engineer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.needs_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-liquid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting times for column EARTH_RECEIVED_START_TIME.\n",
      "Converting times for column EARTH_RECEIVED_STOP_TIME.\n",
      "Converting times for column IMAGE_MID_TIME.\n",
      "Converting times for column IMAGE_TIME.\n",
      "Converting times for column PRODUCT_CREATION_TIME.\n",
      "Converting times for column START_TIME.\n",
      "Converting times for column STOP_TIME.\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maye/miniconda3/envs/py38/lib/python3.8/site-packages/pandas/core/generic.py:2605: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['FILE_NAME', 'FILE_SPECIFICATION_NAME', 'VOLUME_ID',\n",
      "       'ANTIBLOOMING_STATE_FLAG', 'CALIBRATION_LAMP_STATE_FLAG',\n",
      "       'COMMAND_FILE_NAME', 'DATA_CONVERSION_TYPE', 'DATA_SET_ID',\n",
      "       'DELAYED_READOUT_FLAG', 'DESCRIPTION', 'FILTER_NAME_1', 'FILTER_NAME_2',\n",
      "       'GAIN_MODE_ID', 'IMAGE_OBSERVATION_TYPE', 'INSTRUMENT_HOST_NAME',\n",
      "       'INSTRUMENT_ID', 'INSTRUMENT_MODE_ID', 'INSTRUMENT_NAME',\n",
      "       'INST_CMPRS_TYPE', 'LIGHT_FLOOD_STATE_FLAG', 'METHOD_DESC',\n",
      "       'MISSING_PACKET_FLAG', 'MISSION_NAME', 'MISSION_PHASE_NAME',\n",
      "       'OBSERVATION_ID', 'PRODUCT_ID', 'PRODUCT_VERSION_TYPE', 'SEQUENCE_ID',\n",
      "       'SEQUENCE_TITLE', 'SHUTTER_MODE_ID', 'SHUTTER_STATE_ID',\n",
      "       'SOFTWARE_VERSION_ID', 'TARGET_DESC', 'TARGET_NAME',\n",
      "       'TELEMETRY_FORMAT_ID', 'COORDINATE_SYSTEM_NAME', 'RINGS_FLAG',\n",
      "       'SPICE_PRODUCT_ID', 'TARGET_LIST', 'DATA_SET_NAME',\n",
      "       'INSTRUMENT_HOST_ID', 'PRODUCT_TYPE', 'STANDARD_DATA_PRODUCT_ID'],\n",
      "      dtype='object')]\n",
      "\n",
      "  pytables.to_hdf(\n"
     ]
    }
   ],
   "source": [
    "index.convert_to_hdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-cinema",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = index.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-breach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 407299 entries, 0 to 407298\n",
      "Columns: 140 entries, FILE_NAME to STANDARD_DATA_PRODUCT_ID\n",
      "dtypes: datetime64[ns](7), float64(70), int64(20), object(43)\n",
      "memory usage: 438.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-divide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALIBRATION_LAMP_STATE_FLAG\n",
      "DESCRIPTION\n",
      "METHOD_DESC\n",
      "TARGET_LIST\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['CALIBRATION_LAMP_STATE_FLAG', 'DESCRIPTION', 'METHOD_DESC', 'TARGET_LIST']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_mixed_type_cols(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-roads",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 407299 entries, 0 to 407298\n",
      "Columns: 140 entries, FILE_NAME to STANDARD_DATA_PRODUCT_ID\n",
      "dtypes: Float64(70), Int64(20), datetime64[ns](7), string(43)\n",
      "memory usage: 473.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.VOLUME_ID = df.VOLUME_ID.astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-helicopter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 407299 entries, 0 to 407298\n",
      "Columns: 140 entries, FILE_NAME to STANDARD_DATA_PRODUCT_ID\n",
      "dtypes: Float64(70), Int64(20), category(1), datetime64[ns](7), string(42)\n",
      "memory usage: 470.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-hardwood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FILE_NAME                     string\n",
       "FILE_SPECIFICATION_NAME       string\n",
       "VOLUME_ID                   category\n",
       "ANTIBLOOMING_STATE_FLAG       string\n",
       "BIAS_STRIP_MEAN              Float64\n",
       "                              ...   \n",
       "UPPER_RIGHT_LONGITUDE        Float64\n",
       "DATA_SET_NAME                 string\n",
       "INSTRUMENT_HOST_ID            string\n",
       "PRODUCT_TYPE                  string\n",
       "STANDARD_DATA_PRODUCT_ID      string\n",
       "Length: 140, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ANTIBLOOMING_STATE_FLAG = df.ANTIBLOOMING_STATE_FLAG.astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-craps",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-cemetery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Float64Dtype()"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.EMISSION_ANGLE.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-marathon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-peripheral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cassini.iss.index]\n",
      "url = \"https://pds-rings.seti.org/holdings/metadata/COISS_2xxx/COISS_2999/COISS_2999_index.lbl\"\n",
      "timestamp = \"2019-11-19T23:37:22\"\n",
      "\n",
      "[cassini.iss.inventory]\n",
      "url = \"https://pds-rings.seti.org/holdings/metadata/COISS_2xxx/COISS_2999/COISS_2999_inventory.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[cassini.iss.moon_summary]\n",
      "url = \"https://pds-rings.seti.org/holdings/metadata/COISS_2xxx/COISS_2999/COISS_2999_moon_summary.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[cassini.iss.ring_summary]\n",
      "url = \"https://pds-rings.seti.org/holdings/metadata/COISS_2xxx/COISS_2999/COISS_2999_ring_summary.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[cassini.iss.saturn_summary]\n",
      "url = \"https://pds-rings.seti.org/holdings/metadata/COISS_2xxx/COISS_2999/COISS_2999_saturn_summary.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[cassini.uvis.index]\n",
      "url = \"https://pds-rings.seti.org/holdings/metadata/COUVIS_0xxx/COUVIS_0999/COUVIS_0999_index.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[cassini.uvis.moon_summary]\n",
      "url = \"https://pds-rings.seti.org/holdings/metadata/COUVIS_0xxx/COUVIS_0999/COUVIS_0999_moon_summary.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[cassini.uvis.ring_summary]\n",
      "url = \"https://pds-rings.seti.org/holdings/metadata/COUVIS_0xxx/COUVIS_0999/COUVIS_0999_ring_summary.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[cassini.uvis.saturn_summary]\n",
      "url = \"https://pds-rings.seti.org/holdings/metadata/COUVIS_0xxx/COUVIS_0999/COUVIS_0999_saturn_summary.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[cassini.uvis.supplemental_index]\n",
      "url = \"https://pds-rings.seti.org/holdings/metadata/COUVIS_0xxx/COUVIS_0999/COUVIS_0999_supplemental_index.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[mro.hirise.dtm]\n",
      "url = \"https://hirise-pds.lpl.arizona.edu/PDS/INDEX/DTMCUMINDEX.LBL\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[mro.hirise.edr]\n",
      "url = \"https://hirise-pds.lpl.arizona.edu/PDS/INDEX/EDRCUMINDEX.LBL\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[mro.hirise.rdr]\n",
      "url = \"https://hirise-pds.lpl.arizona.edu/PDS/INDEX/RDRCUMINDEX.LBL\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[lro.diviner.edr1]\n",
      "url = \"https://pds-geosciences.wustl.edu/lro/lro-l-dlre-2-edr-v1/lrodlr_0001/index/index.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[lro.diviner.edr2]\n",
      "url = \"https://pds-geosciences.wustl.edu/lro/lro-l-dlre-2-edr-v1/lrodlr_0002/index/index.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[lro.diviner.rdr1]\n",
      "url = \"https://pds-geosciences.wustl.edu/lro/lro-l-dlre-4-rdr-v1/lrodlr_1001/index/rdrindex.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[lro.diviner.rdr2]\n",
      "url = \"https://pds-geosciences.wustl.edu/lro/lro-l-dlre-4-rdr-v1/lrodlr_1002/index/rdrindex.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[lro.lola.edr]\n",
      "url = \"http://pds-geosciences.wustl.edu/lro/lro-l-lola-2-edr-v1/lrolol_0xxx/index/edrindex.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "[lro.lola.rdr]\n",
      "url = \"http://pds-geosciences.wustl.edu/lro/lro-l-lola-3-rdr-v1/lrolol_1xxx/index/rdrindex.lbl\"\n",
      "timestamp = \"\"\n",
      "\n",
      "Use indices.download('mission.instrument.index') to download in index file.\n",
      "For example: indices.download('cassini.uvis.moon_summary'\n"
     ]
    }
   ],
   "source": [
    "indexdb.list_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-subscriber",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

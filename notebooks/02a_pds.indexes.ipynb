{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-oakland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp pds.indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-swedish",
   "metadata": {},
   "source": [
    "# PDS Indexes\n",
    "\n",
    "> Support tools to work with PDS index files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import copy\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlsplit, urlunsplit\n",
    "\n",
    "import pandas as pd\n",
    "import pvl\n",
    "from dateutil import parser\n",
    "from planetarypy import utils\n",
    "from planetarypy.pds.ctx_index import CTXIndex\n",
    "from planetarypy.config import config\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "try:\n",
    "    # 3.6 compatibility\n",
    "    from importlib_resources import path as resource_path\n",
    "except ModuleNotFoundError:\n",
    "    from importlib.resources import path as resource_path\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "storage_root = Path(config.storage_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfb2fdb-fa60-4ab1-80a0-e847d0d95a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "dynamic_urls = {\n",
    "    'mro.ctx' : CTXIndex\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-humanitarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/maye/big_drive/planetary_data')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "storage_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-nancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class PVLColumn:\n",
    "    \"\"\"Manages just one of the columns in a table that is described via PVL.\"\"\"\n",
    "\n",
    "    def __init__(self, pvlobj):\n",
    "        self.pvlobj = pvlobj\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self.pvlobj[\"NAME\"]\n",
    "\n",
    "    @property\n",
    "    def name_as_list(self):\n",
    "        \"needs to return a list for consistency for cases when it's an array.\"\n",
    "        if self.items is None:\n",
    "            return [self.name]\n",
    "        else:\n",
    "            return [self.name + \"_\" + str(i + 1) for i in range(self.items)]\n",
    "\n",
    "    @property\n",
    "    def start(self):\n",
    "        \"Decrease by one as Python is 0-indexed.\"\n",
    "        return self.pvlobj[\"START_BYTE\"] - 1\n",
    "\n",
    "    @property\n",
    "    def stop(self):\n",
    "        return self.start + self.pvlobj[\"BYTES\"]\n",
    "\n",
    "    @property\n",
    "    def items(self):\n",
    "        return self.pvlobj.get(\"ITEMS\")\n",
    "\n",
    "    @property\n",
    "    def item_bytes(self):\n",
    "        return self.pvlobj.get(\"ITEM_BYTES\")\n",
    "\n",
    "    @property\n",
    "    def item_offset(self):\n",
    "        return self.pvlobj.get(\"ITEM_OFFSET\")\n",
    "\n",
    "    @property\n",
    "    def colspecs(self):\n",
    "        if self.items is None:\n",
    "            return (self.start, self.stop)\n",
    "        else:\n",
    "            i = 0\n",
    "            bucket = []\n",
    "            for _ in range(self.items):\n",
    "                off = self.start + self.item_offset * i\n",
    "                bucket.append((off, off + self.item_bytes))\n",
    "                i += 1\n",
    "            return bucket\n",
    "\n",
    "    def decode(self, linedata):\n",
    "        if self.items is None:\n",
    "            start, stop = self.colspecs\n",
    "            return linedata[start:stop]\n",
    "        else:\n",
    "            bucket = []\n",
    "            for (start, stop) in self.colspecs:\n",
    "                bucket.append(linedata[start:stop])\n",
    "            return bucket\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.pvlobj.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class IndexLabel(object):\n",
    "    \"\"\"Support working with label files of PDS Index tables.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labelpath : str, pathlib.Path\n",
    "        Path to the labelfile for a PDS Indexfile. The actual table should reside in the same\n",
    "        folder to be automatically parsed when calling the `read_index_data` method.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, labelpath):\n",
    "        self.path = Path(labelpath)\n",
    "        \"search for table name pointer and store key and fpath.\"\n",
    "        tuple = [i for i in self.pvl_lbl if i[0].startswith(\"^\")][0]\n",
    "        self.tablename = tuple[0][1:]\n",
    "        self.index_name = tuple[1]\n",
    "\n",
    "    @property\n",
    "    def index_path(self):\n",
    "        p = self.path.parent / self.index_name\n",
    "        if not p.exists():\n",
    "            import warnings\n",
    "            warnings.warn(\"Fudging to lower case.\")\n",
    "            p = self.path.parent / self.index_name.lower()\n",
    "        if not p.exists():\n",
    "            warnings.warn(\"`index_path` still doesn't exist.\")\n",
    "        return p\n",
    "    \n",
    "    @property\n",
    "    def pvl_lbl(self):\n",
    "        return pvl.load(str(self.path))\n",
    "\n",
    "    @property\n",
    "    def table(self):\n",
    "        return self.pvl_lbl[self.tablename]\n",
    "\n",
    "    @property\n",
    "    def pvl_columns(self):\n",
    "        return self.table.getlist(\"COLUMN\")\n",
    "\n",
    "    @property\n",
    "    def columns_dic(self):\n",
    "        return {col[\"NAME\"]: col for col in self.pvl_columns}\n",
    "\n",
    "    @property\n",
    "    def colnames(self):\n",
    "        \"\"\"Read the columns in an PDS index label file.\n",
    "\n",
    "        The label file for the PDS indices describes the content\n",
    "        of the index files.\n",
    "        \"\"\"\n",
    "        colnames = []\n",
    "        for col in self.pvl_columns:\n",
    "            colnames.extend(PVLColumn(col).name_as_list)\n",
    "        return colnames\n",
    "\n",
    "    @property\n",
    "    def colspecs(self):\n",
    "        colspecs = []\n",
    "        columns = self.table.getlist(\"COLUMN\")\n",
    "        for column in columns:\n",
    "            pvlcol = PVLColumn(column)\n",
    "            if pvlcol.items is None:\n",
    "                colspecs.append(pvlcol.colspecs)\n",
    "            else:\n",
    "                colspecs.extend(pvlcol.colspecs)\n",
    "        return colspecs\n",
    "\n",
    "    def read_index_data(self, convert_times=True):\n",
    "        return index_to_df(self.index_path, self, convert_times=convert_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def index_to_df(indexpath, label, convert_times=True):\n",
    "    \"\"\"The main reader function for PDS Indexfiles.\n",
    "\n",
    "    In conjunction with an IndexLabel object that figures out the column widths,\n",
    "    this reader should work for all PDS TAB files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    indexpath : str or pathlib.Path\n",
    "        The path to the index TAB file.\n",
    "    label : pdstools.IndexLabel object\n",
    "        Label object that has both the column names and the columns widths as attributes\n",
    "        'colnames' and 'colspecs'\n",
    "    convert_times : bool\n",
    "        Switch to control if to convert columns with \"TIME\" in name (unless COUNT is as well in name) to datetime\n",
    "    \"\"\"\n",
    "    indexpath = Path(indexpath)\n",
    "    df = pd.read_fwf(\n",
    "        indexpath, header=None, names=label.colnames, colspecs=label.colspecs\n",
    "    )\n",
    "    if convert_times:\n",
    "        for column in [i for i in df.columns if \"TIME\" in i and \"COUNT\" not in i]:\n",
    "            if column == \"LOCAL_TIME\":\n",
    "                # don't convert local time\n",
    "                continue\n",
    "            print(f\"Converting times for column {column}.\")\n",
    "            try:\n",
    "                df[column] = pd.to_datetime(df[column])\n",
    "            except ValueError:\n",
    "                df[column] = pd.to_datetime(\n",
    "                    df[column], format=utils.nasa_dt_format_with_ms, errors=\"coerce\"\n",
    "                )\n",
    "        print(\"Done.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-entertainment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Index:\n",
    "    \"\"\"Index manager class.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    key : str\n",
    "        Nested key in form of mission.instrument.indexes.index_name\n",
    "    url : str, optional\n",
    "        URL to index. If not given, will be read from config object.\n",
    "    timestamp : str\n",
    "        Timestamp in ISO time format yy-mm-ddTHH:MM:SS.\n",
    "        This is read from the config object. Its value is the time of the last\n",
    "        download.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, key, url=None):\n",
    "        self.key = key if key.startswith('mission') else \"missions.\"+key\n",
    "        self.set_url(url)\n",
    "        self.timestamp = config.get_value(self.key)[\"timestamp\"]\n",
    "        self.new_timestamp = None  # filled by needs_download()\n",
    "\n",
    "    def set_url(self, url):\n",
    "        try:\n",
    "            self.url = config.get_value(self.key)[\"url\"] if url is None else url\n",
    "        except KeyError:\n",
    "            self.url = dynamic_urls[self.instrument_key]().latest_index_label_url\n",
    "        \n",
    "    @property\n",
    "    def needs_download(self):\n",
    "        \"\"\"Determine if the index needs to be downloaded.\n",
    "\n",
    "        Download shall happen when\n",
    "        (1) no local timestamp was stored or\n",
    "        (2) when the remote timestamp is newer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        index : indices.Index (namedtuple)\n",
    "            Index holding the timestamp attribute read from the config file\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        bool\n",
    "            Boolean indicating if download shall happen.\n",
    "        \"\"\"\n",
    "        remote_timestamp = utils.get_remote_timestamp(self.url)\n",
    "        self.new_timestamp = remote_timestamp\n",
    "        if self.timestamp:\n",
    "            if remote_timestamp > parser.parse(self.timestamp):\n",
    "                return True\n",
    "        else:\n",
    "            # also return True when the timestamp is not valid\n",
    "            return True\n",
    "        # all other cases no D/L required\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def key_tokens(self):\n",
    "        return self.key.split(\".\")\n",
    "\n",
    "    @property\n",
    "    def mission(self):\n",
    "        return self.key_tokens[1]\n",
    "\n",
    "    @property\n",
    "    def mission_key(self):\n",
    "        return '.'.join(self.key_tokens[1:2])\n",
    "\n",
    "    @property\n",
    "    def instrument(self):\n",
    "        return self.key_tokens[2]\n",
    "\n",
    "    @property\n",
    "    def instrument_key(self):\n",
    "        return '.'.join(self.key_tokens[1:3])\n",
    "\n",
    "    @property\n",
    "    def index_name(self):\n",
    "        \"str: Examples: EDR, RDR, moon_summary\"\n",
    "        return self.key_tokens[3]\n",
    "\n",
    "    @property\n",
    "    def label_filename(self):\n",
    "        return Path(self.url.split(\"/\")[-1])\n",
    "\n",
    "    @property\n",
    "    def isupper(self):\n",
    "        return self.label_filename.suffix.isupper()\n",
    "\n",
    "    @property\n",
    "    def table_filename(self):\n",
    "        new_suffix = \".TAB\" if self.isupper else \".tab\"\n",
    "        return self.label_filename.with_suffix(new_suffix)\n",
    "\n",
    "    @property\n",
    "    def label_path(self):\n",
    "        return Path(urlsplit(self.url).path)\n",
    "\n",
    "    @property\n",
    "    def table_path(self):\n",
    "        return self.label_path.with_name(self.table_filename.name)\n",
    "\n",
    "    @property\n",
    "    def table_url(self):\n",
    "        tokens = urlsplit(self.url)\n",
    "        return urlunsplit(\n",
    "            tokens._replace(\n",
    "                path=str(self.label_path.with_name(self.table_filename.name))\n",
    "            )\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def local_dir(self):\n",
    "        p = storage_root / str(self.key).replace(\".\", \"/\")\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "        return p\n",
    "\n",
    "    @property\n",
    "    def local_table_path(self):\n",
    "        return self.local_dir / self.table_filename\n",
    "\n",
    "    @property\n",
    "    def local_label_path(self):\n",
    "        return self.local_dir / self.label_filename\n",
    "\n",
    "    @property\n",
    "    def local_hdf_path(self):\n",
    "        return self.local_table_path.with_suffix(\".hdf\")\n",
    "\n",
    "    @property\n",
    "    def df(self):\n",
    "        return pd.read_hdf(self.local_hdf_path)\n",
    "\n",
    "    def download(self, local_dir=\"\", convert_to_hdf=True, force_update=False):\n",
    "        \"\"\"Wrapping URLs for downloading PDS indices and their label files.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        key : str, optional\n",
    "            Period-separated key into the available index files, e.g. cassini.uvis.moon_summary\n",
    "        label_url : str, optional\n",
    "            Alternative to using the index system, the user can provide the URL to a label\n",
    "            for an index. The table file has to be in the same folder, as usual.\n",
    "        local_dir: str, pathlib.Path, optional\n",
    "            Path for local storage. Default: current directory and filename from URL\n",
    "        convert_to_hdf : bool\n",
    "            Switch to convert the index automatically to a faster loading HDF file\n",
    "        \"\"\"\n",
    "        if not local_dir:\n",
    "            local_dir = self.local_dir\n",
    "        # check timestamp\n",
    "        if not self.needs_download and not force_update:\n",
    "            print(\"Stored index is up-to-date.\")\n",
    "            return\n",
    "        label_url = self.url\n",
    "        logger.info(\"Downloading %s.\" % label_url)\n",
    "        local_label_path, _ = utils.download(label_url, local_dir)\n",
    "        logger.info(\"Downloading %s.\", self.table_url)\n",
    "        local_data_path, _ = utils.download(self.table_url, local_dir)\n",
    "        self.update_timestamp()\n",
    "        if convert_to_hdf is True:\n",
    "            self.convert_to_hdf()\n",
    "            print(f\"Downloaded and converted to pandas HDF:\\n{self.local_hdf_path}\")\n",
    "        else:\n",
    "            print(f\"Downloaded {local_label_path} and {local_data_path}\")\n",
    "\n",
    "    def update_timestamp(self):\n",
    "        # Note: the config object writes itself out after setting any value\n",
    "        config.set_value(f\"{self.key}.timestamp\", self.new_timestamp.isoformat())\n",
    "\n",
    "    def convert_to_hdf(self):\n",
    "        label = IndexLabel(self.local_label_path)\n",
    "        df = label.read_index_data()\n",
    "        df.to_hdf(self.local_hdf_path, \"df\")\n",
    "\n",
    "    def __str__(self):\n",
    "        s = f\"Key: {self.key}\\n\"\n",
    "        s += f\"URL: {self.url}\\n\"\n",
    "        s += f\"Timestamp: {self.timestamp}\\n\"\n",
    "        return s\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de51298-40f3-475d-9bdf-24d6a110c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'missions.cassini.iss.indexes.moon_summary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238e9b89-c0f9-4548-a641-e1a070454f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = Index(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c67a63-9101-4730-8fd9-1eb6d9cea224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Key: missions.cassini.iss.indexes.moon_summary\n",
       "URL: https://pds-rings.seti.org/holdings/metadata/COISS_2xxx/COISS_2999/COISS_2999_moon_summary.lbl\n",
       "Timestamp: 2021-07-20T11:00:52.975329"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1391e9-59d1-4f6d-a4eb-9e5c20f7fcd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cassini'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.mission_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eea1a5a-f0da-4bc7-8e95-f4bffa8ecd3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/maye/big_drive/planetary_data/missions/cassini/iss/indexes/moon_summary')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.local_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ccdfbe-3894-4f3a-9e40-e1300aeb171d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.needs_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4623c656-0b98-45c4-91df-e198a974f468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored index is up-to-date.\n"
     ]
    }
   ],
   "source": [
    "index.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651152c3-10b9-4137-86d5-24055ca36f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13bee96cc97244f6a629589ee97c0214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COISS_2999_moon_summary.lbl: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d2c2716d2c48ea8d0cc83b37421571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COISS_2999_moon_summary.tab: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Downloaded and converted to pandas HDF:\n",
      "/home/maye/big_drive/planetary_data/missions/cassini/iss/indexes/moon_summary/COISS_2999_moon_summary.hdf\n"
     ]
    }
   ],
   "source": [
    "index.download(force_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def decode_line(linedata, labelpath):\n",
    "    \"\"\"Decode one line of tabbed data with the appropriate label file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    linedata : str\n",
    "        One line of a .tab data file\n",
    "    labelpath : str or pathlib.Path\n",
    "        Path to the appropriate label that describes the data.\n",
    "    \"\"\"\n",
    "    label = IndexLabel(labelpath)\n",
    "    for column in label.pvl_columns:\n",
    "        pvlcol = PVLColumn(column)\n",
    "        print(pvlcol.name, pvlcol.decode(linedata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def find_mixed_type_cols(df, fix=True):\n",
    "    \"\"\"For a given dataframe, find the columns that are of mixed type.\n",
    "\n",
    "    Tool to help with the performance warning when trying to save a pandas DataFrame as a HDF.\n",
    "    When a column changes datatype somewhere, pickling occurs, slowing down the reading process of the HDF file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Dataframe to be searched for mixed data-types\n",
    "    fix : bool\n",
    "        Switch to control if NaN values in these problem columns should be replaced by the string 'UNKNOWN'\n",
    "    Returns\n",
    "    -------\n",
    "    List of column names that have data type changes within themselves.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for col in df.columns:\n",
    "        weird = (df[[col]].applymap(type) != df[[col]].iloc[0].apply(type)).any(axis=1)\n",
    "        if len(df[weird]) > 0:\n",
    "            print(col)\n",
    "            result.append(col)\n",
    "    if fix is True:\n",
    "        for col in result:\n",
    "            df[col].fillna(\"UNKNOWN\", inplace=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-alberta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def fix_hirise_edrcumindex(infname, outfname):\n",
    "    \"\"\"Fix HiRISE EDRCUMINDEX.\n",
    "\n",
    "    The HiRISE EDRCUMINDEX has some broken lines where the SCAN_EXPOSURE_DURATION is of format\n",
    "    F10.4 instead of the defined F9.4.\n",
    "    This function simply replaces those incidences with one less decimal fraction, so 20000.0000\n",
    "    becomes 20000.000.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    infname : str\n",
    "        Path to broken EDRCUMINDEX.TAB\n",
    "    outfname : str\n",
    "        Path where to store the fixed TAB file\n",
    "    \"\"\"\n",
    "    with open(infname) as f:\n",
    "        with open(outfname, \"w\") as newf:\n",
    "            for line in tqdm(f):\n",
    "                exp = line.split(\",\")[21]\n",
    "                if float(exp) > 9999.999:\n",
    "                    # catching the return of write into dummy variable\n",
    "                    _ = newf.write(line.replace(exp, exp[:9]))\n",
    "                else:\n",
    "                    _ = newf.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-liquid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "index.convert_to_hdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-breach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 385719 entries, 0 to 385718\n",
      "Data columns (total 35 columns):\n",
      " #   Column                                Non-Null Count   Dtype  \n",
      "---  ------                                --------------   -----  \n",
      " 0   VOLUME_ID                             385719 non-null  object \n",
      " 1   FILE_SPECIFICATION_NAME               385719 non-null  object \n",
      " 2   OPUS_ID                               385719 non-null  object \n",
      " 3   TARGET_NAME                           385719 non-null  object \n",
      " 4   MINIMUM_PLANETOCENTRIC_LATITUDE       385719 non-null  float64\n",
      " 5   MAXIMUM_PLANETOCENTRIC_LATITUDE       385719 non-null  float64\n",
      " 6   MINIMUM_PLANETOGRAPHIC_LATITUDE       385719 non-null  float64\n",
      " 7   MAXIMUM_PLANETOGRAPHIC_LATITUDE       385719 non-null  float64\n",
      " 8   MINIMUM_IAU_LONGITUDE                 385719 non-null  float64\n",
      " 9   MAXIMUM_IAU_LONGITUDE                 385719 non-null  float64\n",
      " 10  MINIMUM_LOCAL_HOUR_ANGLE              385719 non-null  float64\n",
      " 11  MAXIMUM_LOCAL_HOUR_ANGLE              385719 non-null  float64\n",
      " 12  MINIMUM_LONGITUDE_WRT_OBSERVER        385719 non-null  float64\n",
      " 13  MAXIMUM_LONGITUDE_WRT_OBSERVER        385719 non-null  float64\n",
      " 14  MINIMUM_FINEST_SURFACE_RESOLUTION     385719 non-null  float64\n",
      " 15  MAXIMUM_FINEST_SURFACE_RESOLUTION     385719 non-null  float64\n",
      " 16  MINIMUM_COARSEST_SURFACE_RESOLUTION   385719 non-null  float64\n",
      " 17  MAXIMUM_COARSEST_SURFACE_RESOLUTION   385719 non-null  float64\n",
      " 18  MINIMUM_SURFACE_DISTANCE              385719 non-null  float64\n",
      " 19  MAXIMUM_SURFACE_DISTANCE              385719 non-null  float64\n",
      " 20  MINIMUM_PHASE_ANGLE                   385719 non-null  float64\n",
      " 21  MAXIMUM_PHASE_ANGLE                   385719 non-null  float64\n",
      " 22  MINIMUM_INCIDENCE_ANGLE               385719 non-null  float64\n",
      " 23  MAXIMUM_INCIDENCE_ANGLE               385719 non-null  float64\n",
      " 24  MINIMUM_EMISSION_ANGLE                385719 non-null  float64\n",
      " 25  MAXIMUM_EMISSION_ANGLE                385719 non-null  float64\n",
      " 26  SUB_SOLAR_PLANETOCENTRIC_LATITUDE     385719 non-null  float64\n",
      " 27  SUB_SOLAR_PLANETOGRAPHIC_LATITUDE     385719 non-null  float64\n",
      " 28  SUB_OBSERVER_PLANETOCENTRIC_LATITUDE  385719 non-null  float64\n",
      " 29  SUB_OBSERVER_PLANETOGRAPHIC_LATITUDE  385719 non-null  float64\n",
      " 30  SUB_SOLAR_IAU_LONGITUDE               385719 non-null  float64\n",
      " 31  SUB_OBSERVER_IAU_LONGITUDE            385719 non-null  float64\n",
      " 32  CENTER_RESOLUTION                     385719 non-null  float64\n",
      " 33  CENTER_DISTANCE                       385719 non-null  float64\n",
      " 34  CENTER_PHASE_ANGLE                    385719 non-null  float64\n",
      "dtypes: float64(31), object(4)\n",
      "memory usage: 105.9+ MB\n"
     ]
    }
   ],
   "source": [
    "index.df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-subscriber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Key: missions.cassini.iss.indexes.moon_summary\n",
       "URL: https://pds-rings.seti.org/holdings/metadata/COISS_2xxx/COISS_2999/COISS_2999_moon_summary.lbl\n",
       "Timestamp: 2019-06-08T16:28:22"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985e0cae-ee60-4c39-936a-852b398d43ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['missions', 'cassini']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.key_tokens[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23430d4-096a-435f-9e65-4a61a8c54c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cassini'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.mission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570b62c3-7a8c-40e2-8087-ef47f4a315ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'missions.cassini'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.mission_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64ab9ec-e2bc-4fbc-942d-6631bfb867b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'missions.cassini.iss'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.instrument_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ba3ef-b980-41f8-91d9-3a93393e3531",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.get_value(index.instrument_key).get('indexer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49c597c-0607-4fa4-85e5-34058e3f21a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping latest release page ...\n",
      "Scraping volumes page ...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-0c952e102e08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mro.ctx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-1f5668259d6b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, key, url)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mission'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"missions.\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timestamp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# filled by needs_download()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'timestamp'"
     ]
    }
   ],
   "source": [
    "index = Index('mro.ctx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0809dc99-9d14-41f9-8e7f-9a7802f7168b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'planetarypy.pds' has no attribute 'ctx_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-ed5c16b5776f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ctx_index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'planetarypy.pds' has no attribute 'ctx_index'"
     ]
    }
   ],
   "source": [
    "getattr(pds, 'ctx_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3781ecd6-0cbc-46e8-8eb0-f8ef29597eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from planetarypy.pds import ctx_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448a4487-7ce9-4b80-809d-16600a7b779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_index."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38] *",
   "language": "python",
   "name": "conda-env-py38-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ff7aba3-ed81-468c-a7f8-a9b10d4fd89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp pds.utils\n",
    "# default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b3b19c-176b-4ec3-8356-127a344bc8a5",
   "metadata": {},
   "source": [
    "# PDS Utils\n",
    "> Utilities used by the `pds` sub-package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9ce5d2f-52a4-44dc-a377-c04a0c49c60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import show_doc  # noqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "822f5338-aa84-4d2c-b409-de69db64f34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from typing import Union\n",
    "from tqdm.auto import tqdm\n",
    "from fastcore.utils import Path\n",
    "\n",
    "import pandas as pd\n",
    "import pvl\n",
    "from planetarypy import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bbda197-6a07-4b86-82fb-7839b2eeb470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class IndexLabel:\n",
    "    \"Support working with label files of PDS Index tables.\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Path to the labelfile for a PDS Indexfile.\n",
    "        # The actual table should reside in the same folder to be automatically parsed\n",
    "        # when calling the `read_index_data` method.\n",
    "        labelpath: Union[str, Path],\n",
    "    ):\n",
    "        self.path = Path(labelpath)\n",
    "        \"search for table name pointer and store key and fpath.\"\n",
    "        tuple = [i for i in self.pvl_lbl if i[0].startswith(\"^\")][0]\n",
    "        self.tablename = tuple[0][1:]\n",
    "        self.index_name = tuple[1]\n",
    "\n",
    "    @property\n",
    "    def index_path(self):\n",
    "        p = self.path.parent / self.index_name\n",
    "        if not p.exists():\n",
    "            import warnings\n",
    "\n",
    "            warnings.warn(\n",
    "                \"Fudging path name to lower case, opposing label value. (PDS data inconsistency)\"\n",
    "            )\n",
    "            p = self.path.parent / self.index_name.lower()\n",
    "        if not p.exists():\n",
    "            warnings.warn(\"`index_path` still doesn't exist.\")\n",
    "        return p\n",
    "\n",
    "    @property\n",
    "    def pvl_lbl(self):\n",
    "        return pvl.load(str(self.path))\n",
    "\n",
    "    @property\n",
    "    def table(self):\n",
    "        return self.pvl_lbl[self.tablename]\n",
    "\n",
    "    @property\n",
    "    def pvl_columns(self):\n",
    "        return self.table.getlist(\"COLUMN\")\n",
    "\n",
    "    @property\n",
    "    def columns_dic(self):\n",
    "        return {col[\"NAME\"]: col for col in self.pvl_columns}\n",
    "\n",
    "    @property\n",
    "    def colnames(self):\n",
    "        \"\"\"Read the columns in an PDS index label file.\n",
    "\n",
    "        The label file for the PDS indices describes the content\n",
    "        of the index files.\n",
    "        \"\"\"\n",
    "        colnames = []\n",
    "        for col in self.pvl_columns:\n",
    "            colnames.extend(PVLColumn(col).name_as_list)\n",
    "        return colnames\n",
    "\n",
    "    @property\n",
    "    def colspecs(self):\n",
    "        colspecs = []\n",
    "        columns = self.table.getlist(\"COLUMN\")\n",
    "        for column in columns:\n",
    "            pvlcol = PVLColumn(column)\n",
    "            if pvlcol.items is None:\n",
    "                colspecs.append(pvlcol.colspecs)\n",
    "            else:\n",
    "                colspecs.extend(pvlcol.colspecs)\n",
    "        return colspecs\n",
    "\n",
    "    def read_index_data(self, convert_times=True):\n",
    "        return index_to_df(self.index_path, self, convert_times=convert_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d905955-8ca2-4438-b37c-aeb17de10f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def index_to_df(\n",
    "    # Path to the index TAB file\n",
    "    indexpath: Union[str, Path],\n",
    "    # Label object that has both the column names and the columns widths as attributes\n",
    "    # 'colnames' and 'colspecs'\n",
    "    label: IndexLabel,\n",
    "    # Switch to control if to convert columns with \"TIME\" in name (unless COUNT is as well in name) to datetime\n",
    "    convert_times=True,\n",
    "):\n",
    "    \"\"\"The main reader function for PDS Indexfiles.\n",
    "\n",
    "    In conjunction with an IndexLabel object that figures out the column widths,\n",
    "    this reader should work for all PDS TAB files.\n",
    "    \"\"\"\n",
    "    indexpath = Path(indexpath)\n",
    "    df = pd.read_fwf(\n",
    "        indexpath, header=None, names=label.colnames, colspecs=label.colspecs\n",
    "    )\n",
    "    if convert_times:\n",
    "        for column in [col for col in df.columns if \"TIME\" in col]:\n",
    "            if column in [\"LOCAL_TIME\", \"DWELL_TIME\"]:\n",
    "                continue\n",
    "            try:\n",
    "                df[column] = pd.to_datetime(df[column])\n",
    "            except ValueError:\n",
    "                df[column] = pd.to_datetime(\n",
    "                    df[column], format=utils.nasa_dt_format_with_ms, errors=\"coerce\"\n",
    "                )\n",
    "            except KeyError:\n",
    "                raise KeyError(f\"{column} not in {df.columns}\")\n",
    "        print(\"Done.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67c188cf-eb4d-40f4-a6ae-e5a054496d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class PVLColumn:\n",
    "    \"Manages just one of the columns in a table that is described via PVL.\"\n",
    "\n",
    "    def __init__(self, pvlobj):\n",
    "        self.pvlobj = pvlobj\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self.pvlobj[\"NAME\"]\n",
    "\n",
    "    @property\n",
    "    def name_as_list(self):\n",
    "        \"needs to return a list for consistency for cases when it's an array.\"\n",
    "        if self.items is None:\n",
    "            return [self.name]\n",
    "        else:\n",
    "            return [self.name + \"_\" + str(i + 1) for i in range(self.items)]\n",
    "\n",
    "    @property\n",
    "    def start(self):\n",
    "        \"Decrease by one as Python is 0-indexed.\"\n",
    "        return self.pvlobj[\"START_BYTE\"] - 1\n",
    "\n",
    "    @property\n",
    "    def stop(self):\n",
    "        return self.start + self.pvlobj[\"BYTES\"]\n",
    "\n",
    "    @property\n",
    "    def items(self):\n",
    "        return self.pvlobj.get(\"ITEMS\")\n",
    "\n",
    "    @property\n",
    "    def item_bytes(self):\n",
    "        return self.pvlobj.get(\"ITEM_BYTES\")\n",
    "\n",
    "    @property\n",
    "    def item_offset(self):\n",
    "        return self.pvlobj.get(\"ITEM_OFFSET\")\n",
    "\n",
    "    @property\n",
    "    def colspecs(self):\n",
    "        if self.items is None:\n",
    "            return (self.start, self.stop)\n",
    "        else:\n",
    "            i = 0\n",
    "            bucket = []\n",
    "            for _ in range(self.items):\n",
    "                off = self.start + self.item_offset * i\n",
    "                bucket.append((off, off + self.item_bytes))\n",
    "                i += 1\n",
    "            return bucket\n",
    "\n",
    "    def decode(self, linedata):\n",
    "        if self.items is None:\n",
    "            start, stop = self.colspecs\n",
    "            return linedata[start:stop]\n",
    "        else:\n",
    "            bucket = []\n",
    "            for (start, stop) in self.colspecs:\n",
    "                bucket.append(linedata[start:stop])\n",
    "            return bucket\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.pvlobj.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bfed330-fe07-4168-9249-d113199b252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def decode_line(\n",
    "    linedata: str,  # One line of a .tab data file\n",
    "    labelpath: Union[\n",
    "        str, Path\n",
    "    ],  # Path to the appropriate label that describes the data.\n",
    "):\n",
    "    \"Decode one line of tabbed data with the appropriate label file.\"\n",
    "    label = IndexLabel(labelpath)\n",
    "    for column in label.pvl_columns:\n",
    "        pvlcol = PVLColumn(column)\n",
    "        print(pvlcol.name, pvlcol.decode(linedata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aed7523a-48f5-4013-93a6-8ed839d073bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def find_mixed_type_cols(\n",
    "    # Dataframe to be searched for mixed data-types\n",
    "    df: pd.DataFrame,\n",
    "    # Switch to control if NaN values in these problem columns should be replaced by the string 'UNKNOWN'\n",
    "    fix: bool = True,\n",
    ") -> list:  # List of column names that have data type changes within themselves.\n",
    "    \"\"\"For a given dataframe, find the columns that are of mixed type.\n",
    "\n",
    "    Tool to help with the performance warning when trying to save a pandas DataFrame as a HDF.\n",
    "    When a column changes datatype somewhere, pickling occurs, slowing down the reading process of the HDF file.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for col in df.columns:\n",
    "        weird = (df[[col]].applymap(type) != df[[col]].iloc[0].apply(type)).any(axis=1)\n",
    "        if len(df[weird]) > 0:\n",
    "            print(col)\n",
    "            result.append(col)\n",
    "    if fix is True:\n",
    "        for col in result:\n",
    "            df[col].fillna(\"UNKNOWN\", inplace=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0468981f-7f85-449d-a230-98d25476b92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def fix_hirise_edrcumindex(\n",
    "    infname: Union[str, Path],  # Path to broken EDRCUMINDEX.TAB\n",
    "    outfname: Union[str, Path],  # Path where to store the fixed TAB file\n",
    "):\n",
    "    \"\"\"Fix HiRISE EDRCUMINDEX.\n",
    "\n",
    "    The HiRISE EDRCUMINDEX has some broken lines where the SCAN_EXPOSURE_DURATION is of format\n",
    "    F10.4 instead of the defined F9.4.\n",
    "    This function simply replaces those incidences with one less decimal fraction, so 20000.0000\n",
    "    becomes 20000.000.\n",
    "    \"\"\"\n",
    "    with Path(infname).open() as f:\n",
    "        with Path(outfname).open(\"w\") as newf:\n",
    "            for line in tqdm(f):\n",
    "                exp = line.split(\",\")[21]\n",
    "                if float(exp) > 9999.999:\n",
    "                    # catching the return of write into dummy variable\n",
    "                    _ = newf.write(line.replace(exp, exp[:9]))\n",
    "                else:\n",
    "                    _ = newf.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e8bfde-7cca-4445-905b-7b5849a8b3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "20a7a740208dd76cb626dd06ce0a8764d024c312b76e69724f0f726a9a6945a7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff7aba3-ed81-468c-a7f8-a9b10d4fd89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp pds.utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b3b19c-176b-4ec3-8356-127a344bc8a5",
   "metadata": {},
   "source": [
    "# PDS Utils\n",
    "> Utilities used by the `pds` sub-package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822f5338-aa84-4d2c-b409-de69db64f34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastcore.utils import Path\n",
    "\n",
    "import pandas as pd\n",
    "import pvl\n",
    "from planetarypy import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d905955-8ca2-4438-b37c-aeb17de10f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def index_to_df(indexpath, label, convert_times=True):\n",
    "    \"\"\"The main reader function for PDS Indexfiles.\n",
    "\n",
    "    In conjunction with an IndexLabel object that figures out the column widths,\n",
    "    this reader should work for all PDS TAB files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    indexpath : str or pathlib.Path\n",
    "        The path to the index TAB file.\n",
    "    label : pdstools.IndexLabel object\n",
    "        Label object that has both the column names and the columns widths as attributes\n",
    "        'colnames' and 'colspecs'\n",
    "    convert_times : bool\n",
    "        Switch to control if to convert columns with \"TIME\" in name (unless COUNT is as well in name) to datetime\n",
    "    \"\"\"\n",
    "    indexpath = Path(indexpath)\n",
    "    df = pd.read_fwf(\n",
    "        indexpath, header=None, names=label.colnames, colspecs=label.colspecs\n",
    "    )\n",
    "    if convert_times:\n",
    "        for column in [col for col in df.columns if \"TIME\" in col]:\n",
    "            if column in [\"LOCAL_TIME\", \"DWELL_TIME\"]:\n",
    "                continue\n",
    "            try:\n",
    "                df[column] = pd.to_datetime(df[column])\n",
    "            except ValueError:\n",
    "                df[column] = pd.to_datetime(\n",
    "                    df[column], format=utils.nasa_dt_format_with_ms, errors=\"coerce\"\n",
    "                )\n",
    "            except KeyError:\n",
    "                raise KeyError(f\"{column} not in {df.columns}\")\n",
    "        print(\"Done.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c188cf-eb4d-40f4-a6ae-e5a054496d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class PVLColumn:\n",
    "    \"\"\"Manages just one of the columns in a table that is described via PVL.\"\"\"\n",
    "\n",
    "    def __init__(self, pvlobj):\n",
    "        self.pvlobj = pvlobj\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self.pvlobj[\"NAME\"]\n",
    "\n",
    "    @property\n",
    "    def name_as_list(self):\n",
    "        \"needs to return a list for consistency for cases when it's an array.\"\n",
    "        if self.items is None:\n",
    "            return [self.name]\n",
    "        else:\n",
    "            return [self.name + \"_\" + str(i + 1) for i in range(self.items)]\n",
    "\n",
    "    @property\n",
    "    def start(self):\n",
    "        \"Decrease by one as Python is 0-indexed.\"\n",
    "        return self.pvlobj[\"START_BYTE\"] - 1\n",
    "\n",
    "    @property\n",
    "    def stop(self):\n",
    "        return self.start + self.pvlobj[\"BYTES\"]\n",
    "\n",
    "    @property\n",
    "    def items(self):\n",
    "        return self.pvlobj.get(\"ITEMS\")\n",
    "\n",
    "    @property\n",
    "    def item_bytes(self):\n",
    "        return self.pvlobj.get(\"ITEM_BYTES\")\n",
    "\n",
    "    @property\n",
    "    def item_offset(self):\n",
    "        return self.pvlobj.get(\"ITEM_OFFSET\")\n",
    "\n",
    "    @property\n",
    "    def colspecs(self):\n",
    "        if self.items is None:\n",
    "            return (self.start, self.stop)\n",
    "        else:\n",
    "            i = 0\n",
    "            bucket = []\n",
    "            for _ in range(self.items):\n",
    "                off = self.start + self.item_offset * i\n",
    "                bucket.append((off, off + self.item_bytes))\n",
    "                i += 1\n",
    "            return bucket\n",
    "\n",
    "    def decode(self, linedata):\n",
    "        if self.items is None:\n",
    "            start, stop = self.colspecs\n",
    "            return linedata[start:stop]\n",
    "        else:\n",
    "            bucket = []\n",
    "            for (start, stop) in self.colspecs:\n",
    "                bucket.append(linedata[start:stop])\n",
    "            return bucket\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.pvlobj.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbda197-6a07-4b86-82fb-7839b2eeb470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class IndexLabel(object):\n",
    "    \"\"\"Support working with label files of PDS Index tables.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labelpath : str, pathlib.Path\n",
    "        Path to the labelfile for a PDS Indexfile. The actual table should reside in the same\n",
    "        folder to be automatically parsed when calling the `read_index_data` method.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, labelpath):\n",
    "        self.path = Path(labelpath)\n",
    "        \"search for table name pointer and store key and fpath.\"\n",
    "        tuple = [i for i in self.pvl_lbl if i[0].startswith(\"^\")][0]\n",
    "        self.tablename = tuple[0][1:]\n",
    "        self.index_name = tuple[1]\n",
    "\n",
    "    @property\n",
    "    def index_path(self):\n",
    "        p = self.path.parent / self.index_name\n",
    "        if not p.exists():\n",
    "            import warnings\n",
    "\n",
    "            warnings.warn(\"Fudging path name to lower case, opposing label value. (PDS data inconsistency)\")\n",
    "            p = self.path.parent / self.index_name.lower()\n",
    "        if not p.exists():\n",
    "            warnings.warn(\"`index_path` still doesn't exist.\")\n",
    "        return p\n",
    "\n",
    "    @property\n",
    "    def pvl_lbl(self):\n",
    "        return pvl.load(str(self.path))\n",
    "\n",
    "    @property\n",
    "    def table(self):\n",
    "        return self.pvl_lbl[self.tablename]\n",
    "\n",
    "    @property\n",
    "    def pvl_columns(self):\n",
    "        return self.table.getlist(\"COLUMN\")\n",
    "\n",
    "    @property\n",
    "    def columns_dic(self):\n",
    "        return {col[\"NAME\"]: col for col in self.pvl_columns}\n",
    "\n",
    "    @property\n",
    "    def colnames(self):\n",
    "        \"\"\"Read the columns in an PDS index label file.\n",
    "\n",
    "        The label file for the PDS indices describes the content\n",
    "        of the index files.\n",
    "        \"\"\"\n",
    "        colnames = []\n",
    "        for col in self.pvl_columns:\n",
    "            colnames.extend(PVLColumn(col).name_as_list)\n",
    "        return colnames\n",
    "\n",
    "    @property\n",
    "    def colspecs(self):\n",
    "        colspecs = []\n",
    "        columns = self.table.getlist(\"COLUMN\")\n",
    "        for column in columns:\n",
    "            pvlcol = PVLColumn(column)\n",
    "            if pvlcol.items is None:\n",
    "                colspecs.append(pvlcol.colspecs)\n",
    "            else:\n",
    "                colspecs.extend(pvlcol.colspecs)\n",
    "        return colspecs\n",
    "\n",
    "    def read_index_data(self, convert_times=True):\n",
    "        return index_to_df(self.index_path, self, convert_times=convert_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfed330-fe07-4168-9249-d113199b252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def decode_line(linedata, labelpath):\n",
    "    \"\"\"Decode one line of tabbed data with the appropriate label file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    linedata : str\n",
    "        One line of a .tab data file\n",
    "    labelpath : str or pathlib.Path\n",
    "        Path to the appropriate label that describes the data.\n",
    "    \"\"\"\n",
    "    label = IndexLabel(labelpath)\n",
    "    for column in label.pvl_columns:\n",
    "        pvlcol = PVLColumn(column)\n",
    "        print(pvlcol.name, pvlcol.decode(linedata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed7523a-48f5-4013-93a6-8ed839d073bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def find_mixed_type_cols(df, fix=True):\n",
    "    \"\"\"For a given dataframe, find the columns that are of mixed type.\n",
    "\n",
    "    Tool to help with the performance warning when trying to save a pandas DataFrame as a HDF.\n",
    "    When a column changes datatype somewhere, pickling occurs, slowing down the reading process of the HDF file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Dataframe to be searched for mixed data-types\n",
    "    fix : bool\n",
    "        Switch to control if NaN values in these problem columns should be replaced by the string 'UNKNOWN'\n",
    "    Returns\n",
    "    -------\n",
    "    List of column names that have data type changes within themselves.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for col in df.columns:\n",
    "        weird = (df[[col]].applymap(type) != df[[col]].iloc[0].apply(type)).any(axis=1)\n",
    "        if len(df[weird]) > 0:\n",
    "            print(col)\n",
    "            result.append(col)\n",
    "    if fix is True:\n",
    "        for col in result:\n",
    "            df[col].fillna(\"UNKNOWN\", inplace=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0468981f-7f85-449d-a230-98d25476b92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def fix_hirise_edrcumindex(infname, outfname):\n",
    "    \"\"\"Fix HiRISE EDRCUMINDEX.\n",
    "\n",
    "    The HiRISE EDRCUMINDEX has some broken lines where the SCAN_EXPOSURE_DURATION is of format\n",
    "    F10.4 instead of the defined F9.4.\n",
    "    This function simply replaces those incidences with one less decimal fraction, so 20000.0000\n",
    "    becomes 20000.000.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    infname : str\n",
    "        Path to broken EDRCUMINDEX.TAB\n",
    "    outfname : str\n",
    "        Path where to store the fixed TAB file\n",
    "    \"\"\"\n",
    "    with open(infname) as f:\n",
    "        with open(outfname, \"w\") as newf:\n",
    "            for line in tqdm(f):\n",
    "                exp = line.split(\",\")[21]\n",
    "                if float(exp) > 9999.999:\n",
    "                    # catching the return of write into dummy variable\n",
    "                    _ = newf.write(line.replace(exp, exp[:9]))\n",
    "                else:\n",
    "                    _ = newf.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e8bfde-7cca-4445-905b-7b5849a8b3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38]",
   "language": "python",
   "name": "conda-env-py38-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
